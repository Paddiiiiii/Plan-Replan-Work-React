from typing import Dict, List, Any, Optional, Tuple
from work.tools import BufferFilterTool, ElevationFilterTool, SlopeFilterTool, VegetationFilterTool, RelativePositionFilterTool, DistanceFilterTool, AreaFilterTool
from context_manager import ContextManager
from config import LLM_CONFIG, GEO_BOUNDS, PATHS, TOOL_ENABLE_CONFIG
from utils.llm_utils import call_llm, parse_plan_response
from utils.tool_utils import get_tools_schema_text, prepare_step_input_path
from utils.geojson_generator import generate_initial_geojson
import json
import logging
import re
from pathlib import Path
from datetime import datetime

logger = logging.getLogger(__name__)

class WorkAgent:
    def __init__(self, context_manager: ContextManager):
        self.context_manager = context_manager
        # æ ¹æ®é…ç½®åªåˆå§‹åŒ–å¯ç”¨çš„å·¥å…·
        all_tools = {
            "buffer_filter_tool": BufferFilterTool(),
            "elevation_filter_tool": ElevationFilterTool(),
            "slope_filter_tool": SlopeFilterTool(),
            "vegetation_filter_tool": VegetationFilterTool(),
            "relative_position_filter_tool": RelativePositionFilterTool(),
            "distance_filter_tool": DistanceFilterTool(),
            "area_filter_tool": AreaFilterTool()
        }
        # åªä¿ç•™å¯ç”¨çš„å·¥å…·
        self.tools = {
            tool_name: tool for tool_name, tool in all_tools.items()
            if TOOL_ENABLE_CONFIG.get(tool_name, True)
        }
        logger.info(f"å·²å¯ç”¨çš„å·¥å…·: {list(self.tools.keys())}")

    def execute_plan(self, plan: Dict) -> Dict[str, Any]:
        """
        æ‰§è¡Œè®¡åˆ’ï¼šåŸºäºKAGçŸ¥è¯†ç”Ÿæˆå·¥å…·è°ƒç”¨è®¡åˆ’ï¼Œç„¶åæ‰§è¡Œ
        
        Args:
            plan: Planæ¨¡å—è¿”å›çš„å­—å…¸ï¼ŒåŒ…å«original_queryã€combined_kag_answersç­‰ä¿¡æ¯
            
        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        # æ£€æŸ¥planæ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨è®¡åˆ’ï¼ˆå‘åå…¼å®¹ï¼‰
        if "steps" in plan or "sub_plans" in plan:
            # å¦‚æœæ˜¯æ—§çš„planæ ¼å¼ï¼ˆç›´æ¥åŒ…å«å·¥å…·è°ƒç”¨è®¡åˆ’ï¼‰ï¼Œç›´æ¥æ‰§è¡Œ
            logger.info("Worké˜¶æ®µ - æ£€æµ‹åˆ°æ—§æ ¼å¼planï¼ˆåŒ…å«å·¥å…·è°ƒç”¨è®¡åˆ’ï¼‰ï¼Œç›´æ¥æ‰§è¡Œ")
            if "sub_plans" in plan:
                return self._execute_sub_plans(plan)
            else:
                return self._execute_single_plan(plan)
        
        # æ–°æ ¼å¼ï¼šplanåŒ…å«é—®é¢˜å’ŒKAGç­”æ¡ˆï¼Œéœ€è¦ç”Ÿæˆå·¥å…·è°ƒç”¨è®¡åˆ’
        original_query = plan.get("original_query", "")
        combined_kag_answers = plan.get("combined_kag_answers", "")
        kag_results = plan.get("kag_results", [])
        
        if not original_query:
            return {
                "success": False,
                "error": "Planä¸­ç¼ºå°‘original_queryå­—æ®µ"
            }
        
        if not combined_kag_answers:
            logger.warning("Worké˜¶æ®µ - combined_kag_answersä¸ºç©ºï¼Œå°†åŸºäºé—®é¢˜æœ¬èº«ç”Ÿæˆå·¥å…·è®¡åˆ’")
        
        logger.info("Worké˜¶æ®µ - å¼€å§‹åŸºäºKAGçŸ¥è¯†ç”Ÿæˆå·¥å…·è°ƒç”¨è®¡åˆ’")
        
        # ç”Ÿæˆå·¥å…·è°ƒç”¨è®¡åˆ’
        tool_plan = self._generate_tool_plan(original_query, combined_kag_answers, kag_results)
        
        if not tool_plan or "error" in tool_plan:
            return {
                "success": False,
                "error": tool_plan.get("error", "æ— æ³•ç”Ÿæˆå·¥å…·è°ƒç”¨è®¡åˆ’")
            }
        
        # å°†åŸå§‹planä¸­çš„kag_resultsç­‰ä¿¡æ¯åˆå¹¶åˆ°tool_planä¸­ï¼Œä¾›å‰ç«¯å±•ç¤º
        tool_plan["original_query"] = original_query
        tool_plan["kag_results"] = kag_results
        tool_plan["combined_kag_answers"] = combined_kag_answers
        # ä¿ç•™planä¸­çš„retrieved_entitieså’Œretrieved_relationsï¼Œç”¨äºä¿å­˜åˆ°kg_graphæ–‡ä»¶å¤¹
        tool_plan["retrieved_entities"] = plan.get("retrieved_entities", [])
        tool_plan["retrieved_relations"] = plan.get("retrieved_relations", [])
        if plan.get("sub_questions"):
            tool_plan["sub_questions"] = plan.get("sub_questions")
        
        # åœ¨ç»ˆç«¯æ˜¾ç¤ºå·¥å…·è°ƒç”¨è®¡åˆ’
        print("\n" + "=" * 80)
        print("ğŸ”§ å·¥å…·è°ƒç”¨è®¡åˆ’ï¼ˆJSONæ ¼å¼ï¼‰")
        print("=" * 80)
        
        display_plan = {}
        if "sub_plans" in tool_plan:
            display_plan["æ¨¡å¼"] = f"å¤šä»»åŠ¡æ¨¡å¼ï¼ˆ{len(tool_plan.get('sub_plans', []))}ä¸ªå­è®¡åˆ’ï¼‰"
            display_plan["sub_plans"] = []
            for sub_plan in tool_plan.get('sub_plans', []):
                display_sub_plan = {
                    "unit": sub_plan.get('unit', 'æœªçŸ¥å•ä½'),
                    "steps": []
                }
                for step in sub_plan.get('steps', []):
                    display_step = {
                        "step_id": step.get('step_id'),
                        "description": step.get('description', 'æ— æè¿°'),
                        "type": step.get('type', 'N/A'),
                        "params": step.get('params', {})
                    }
                    # ç§»é™¤input_geojson_pathï¼ˆç³»ç»Ÿè‡ªåŠ¨å¡«å……ï¼‰
                    if "params" in display_step and "input_geojson_path" in display_step["params"]:
                        del display_step["params"]["input_geojson_path"]
                    display_sub_plan["steps"].append(display_step)
                display_plan["sub_plans"].append(display_sub_plan)
        else:
            display_plan["æ¨¡å¼"] = "å•ä»»åŠ¡æ¨¡å¼"
            display_plan["steps"] = []
            for step in tool_plan.get('steps', []):
                display_step = {
                    "step_id": step.get('step_id'),
                    "description": step.get('description', 'æ— æè¿°'),
                    "type": step.get('type', 'N/A'),
                    "params": step.get('params', {})
                }
                # ç§»é™¤input_geojson_pathï¼ˆç³»ç»Ÿè‡ªåŠ¨å¡«å……ï¼‰
                if "params" in display_step and "input_geojson_path" in display_step["params"]:
                    del display_step["params"]["input_geojson_path"]
                display_plan["steps"].append(display_step)
        
        # æ‰“å°JSONæ ¼å¼çš„è®¡åˆ’
        print(json.dumps(display_plan, ensure_ascii=False, indent=2))
        print("=" * 80 + "\n")
        
        # æ‰§è¡Œå·¥å…·è°ƒç”¨è®¡åˆ’
        if "sub_plans" in tool_plan:
            work_result = self._execute_sub_plans(tool_plan)
        else:
            work_result = self._execute_single_plan(tool_plan)
        
        # å°†æ›´æ–°åçš„planï¼ˆåŒ…å«kag_resultså’ŒLLMå“åº”ï¼‰æ·»åŠ åˆ°work_resultä¸­
        work_result["updated_plan"] = tool_plan
        
        return work_result
    
    def _format_tools_schema_for_prompt(self) -> str:
        """
        æ ¼å¼åŒ–å·¥å…·schemaä¸ºpromptå‹å¥½çš„æ ¼å¼
        
        Returns:
            æ ¼å¼åŒ–çš„å·¥å…·è¯´æ˜æ–‡æœ¬
        """
        tool_descriptions = []
        
        # å·¥å…·ç±»å‹åˆ°å·¥å…·åç§°çš„æ˜ å°„
        type_mapping = {
            "buffer": "buffer_filter_tool",
            "elevation": "elevation_filter_tool",
            "slope": "slope_filter_tool",
            "vegetation": "vegetation_filter_tool",
            "relative_position": "relative_position_filter_tool",
            "distance": "distance_filter_tool",
            "area": "area_filter_tool"
        }
        
        for step_type, tool_name in type_mapping.items():
            # æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨
            if not TOOL_ENABLE_CONFIG.get(tool_name, True):
                continue  # è·³è¿‡æœªå¯ç”¨çš„å·¥å…·
            
            if tool_name in self.tools:
                tool = self.tools[tool_name]
                schema = tool.get_schema()
                
                # æ ¼å¼åŒ–å‚æ•°è¯´æ˜
                params_desc = []
                for param_name, param_info in schema.get("parameters", {}).items():
                    param_type = param_info.get("type", "unknown")
                    param_desc = param_info.get("description", "")
                    if param_name == "input_geojson_path":
                        params_desc.append(f"  - `{param_name}`: {param_desc}ï¼ˆç³»ç»Ÿè‡ªåŠ¨å¡«å……ï¼Œæ— éœ€åœ¨è®¡åˆ’ä¸­æŒ‡å®šï¼‰")
                    else:
                        # åˆ¤æ–­æ˜¯å¦å¿…éœ€å‚æ•°
                        required_params = {
                            "buffer": ["buffer_distance"],
                            "elevation": [],
                            "slope": [],
                            "vegetation": [],
                            "relative_position": ["reference_point", "reference_direction", "position_types"],
                            "distance": ["reference_point", "max_distance"],
                            "area": ["min_area_km2"]
                        }
                        required = param_name in required_params.get(step_type, [])
                        required_text = "å¿…éœ€" if required else "å¯é€‰"
                        params_desc.append(f"  - `{param_name}` ({required_text}, ç±»å‹: {param_type}): {param_desc}")
                
                tool_descriptions.append(
                    f"### å·¥å…·ç±»å‹: `{step_type}`\n"
                    f"- **å·¥å…·åç§°**: {tool_name}\n"
                    f"- **åŠŸèƒ½**: {schema.get('description', '')}\n"
                    f"- **å‚æ•°**:\n" + "\n".join(params_desc)
                )
        
        return "\n\n".join(tool_descriptions)
    
    def _generate_tool_plan(self, user_query: str, kag_answers: str, kag_results: List[Dict] = None) -> Dict:
        """
        åŸºäºç”¨æˆ·é—®é¢˜å’ŒKAGçŸ¥è¯†ç”Ÿæˆå·¥å…·è°ƒç”¨è®¡åˆ’ï¼ˆä¸¤è½®æ€è€ƒæ¨¡å¼ï¼‰
        
        Args:
            user_query: ç”¨æˆ·åŸå§‹é—®é¢˜
            kag_answers: KAGåˆå¹¶åçš„ç­”æ¡ˆæ–‡æœ¬
            kag_results: KAGç»“æœåˆ—è¡¨ï¼ˆå¯é€‰ï¼Œç”¨äºæä¾›æ›´å¤šä¸Šä¸‹æ–‡ï¼‰
            
        Returns:
            å·¥å…·è°ƒç”¨è®¡åˆ’å­—å…¸ï¼ˆæ ¼å¼ä¸åŸæ¥planç›¸åŒï¼‰
        """
        # ========== ç¬¬ä¸€è½®æ€è€ƒï¼šå·¥å…·é€‰æ‹©å’Œå‚æ•°æå– ==========
        logger.info("Worké˜¶æ®µ - ç¬¬ä¸€è½®æ€è€ƒï¼šå·¥å…·é€‰æ‹©å’Œå‚æ•°æå–")
        
        first_prompt = self.context_manager.load_static_context("work_first_think_prompt")
        
        # æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼ŒåŒ…å«é—®é¢˜å’ŒKAGçŸ¥è¯†
        knowledge_text = f"\n\nKAGçŸ¥è¯†åº“æ£€ç´¢ç»“æœ:\n{kag_answers}" if kag_answers else ""
        
        # å¦‚æœæœ‰kag_resultsï¼Œæä¾›æ›´è¯¦ç»†çš„ä¿¡æ¯
        if kag_results:
            knowledge_text += "\n\nè¯¦ç»†KAGæ£€ç´¢ç»“æœ:\n"
            for i, result in enumerate(kag_results, 1):
                question = result.get("question", "")
                answer = result.get("answer", "")
                if answer:
                    knowledge_text += f"\nå­é—®é¢˜{i}: {question}\nç­”æ¡ˆ{i}: {answer}\n"
        
        first_user_content = f"ç”¨æˆ·ä»»åŠ¡: {user_query}{knowledge_text}\n\nè¯·åˆ†æéœ€è¦å“ªäº›å·¥å…·ï¼Œå¹¶æå–å…·ä½“çš„å‚æ•°å€¼ã€‚åœ¨å“åº”æœ€åè¾“å‡ºJSONæ ¼å¼çš„å·¥å…·é€‰æ‹©å’Œå‚æ•°ã€‚"
        
        first_messages = [
            {"role": "system", "content": first_prompt},
            {"role": "user", "content": first_user_content}
        ]
        
        logger.info(f"Worké˜¶æ®µ - ç¬¬ä¸€è½®LLMè°ƒç”¨ï¼Œç”¨æˆ·é—®é¢˜: {user_query[:100]}...")
        first_response = call_llm(first_messages)
        logger.info(f"Worké˜¶æ®µ - ç¬¬ä¸€è½®LLMå“åº”é•¿åº¦: {len(first_response)}")
        
        # è§£æç¬¬ä¸€è½®æ€è€ƒçš„ç»“æœ
        first_think_result = self._parse_first_think_response(first_response)
        if not first_think_result or "error" in first_think_result:
            logger.error(f"Worké˜¶æ®µ - ç¬¬ä¸€è½®æ€è€ƒå¤±è´¥: {first_think_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return {
                "error": "ç¬¬ä¸€è½®æ€è€ƒå¤±è´¥",
                "error_detail": first_think_result.get("error", "æ— æ³•è§£æç¬¬ä¸€è½®æ€è€ƒç»“æœ")
            }
        
        logger.info(f"Worké˜¶æ®µ - ç¬¬ä¸€è½®æ€è€ƒæˆåŠŸï¼Œå·¥å…·æ•°é‡: {len(first_think_result.get('tools', []))}")
        
        # ========== ç¬¬äºŒè½®æ€è€ƒï¼šç¼–ç»‡å·¥å…·è°ƒç”¨è®¡åˆ’ ==========
        logger.info("Worké˜¶æ®µ - ç¬¬äºŒè½®æ€è€ƒï¼šç¼–ç»‡å·¥å…·è°ƒç”¨è®¡åˆ’")
        
        second_prompt = self.context_manager.load_static_context("work_second_think_prompt")
        
        # å°†ç¬¬ä¸€è½®æ€è€ƒç»“æœæ ¼å¼åŒ–ä¸ºJSONå­—ç¬¦ä¸²
        first_think_json = json.dumps(first_think_result, ensure_ascii=False, indent=2)
        
        second_user_content = f"""ç”¨æˆ·ä»»åŠ¡: {user_query}

ç¬¬ä¸€è½®æ€è€ƒç»“æœï¼ˆå·¥å…·é€‰æ‹©å’Œå‚æ•°ï¼‰:
```json
{first_think_json}
```

è¯·åŸºäºç¬¬ä¸€è½®æ€è€ƒçš„ç»“æœï¼Œç”Ÿæˆæ ‡å‡†çš„å·¥å…·è°ƒç”¨è®¡åˆ’ï¼ˆstepsæ ¼å¼ï¼‰ã€‚åœ¨å“åº”æœ€åè¾“å‡ºJSONæ ¼å¼çš„è®¡åˆ’ã€‚"""
        
        second_messages = [
            {"role": "system", "content": second_prompt},
            {"role": "user", "content": second_user_content}
        ]
        
        logger.info("Worké˜¶æ®µ - ç¬¬äºŒè½®LLMè°ƒç”¨")
        second_response = call_llm(second_messages)
        logger.info(f"Worké˜¶æ®µ - ç¬¬äºŒè½®LLMå“åº”é•¿åº¦: {len(second_response)}")
        
        # è§£æç¬¬äºŒè½®æ€è€ƒçš„ç»“æœ
        tool_plan = parse_plan_response(second_response)
        
        # éªŒè¯è®¡åˆ’æ ¼å¼
        if not tool_plan or ("steps" not in tool_plan and "sub_plans" not in tool_plan):
            logger.error(f"Worké˜¶æ®µ - æ— æ³•è§£æå·¥å…·è°ƒç”¨è®¡åˆ’")
            logger.error(f"Worké˜¶æ®µ - å®Œæ•´LLMå“åº”é•¿åº¦: {len(second_response)}")
            logger.error(f"Worké˜¶æ®µ - LLMå“åº”å¼€å¤´500å­—ç¬¦: {second_response[:500]}")
            logger.error(f"Worké˜¶æ®µ - LLMå“åº”ç»“å°¾1000å­—ç¬¦: {second_response[-1000:]}")
            return {
                "error": "æ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„å·¥å…·è°ƒç”¨è®¡åˆ’",
                "llm_response": second_response,
                "error_detail": "ç¬¬äºŒè½®æ€è€ƒä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼å·¥å…·è°ƒç”¨è®¡åˆ’"
            }
        
        # éªŒè¯è®¡åˆ’çš„æœ‰æ•ˆæ€§å’Œå·¥å…·å‚æ•°
        validation_result = self._validate_tool_plan(tool_plan)
        if not validation_result.get("valid"):
            error_msg = validation_result.get("error", "æœªçŸ¥éªŒè¯é”™è¯¯")
            logger.error(f"Worké˜¶æ®µ - å·¥å…·è°ƒç”¨è®¡åˆ’éªŒè¯å¤±è´¥: {error_msg}")
            logger.error(f"Worké˜¶æ®µ - å·¥å…·è®¡åˆ’å†…å®¹: {json.dumps(tool_plan, ensure_ascii=False, indent=2)[:1000]}")
            return {
                "error": "å·¥å…·è°ƒç”¨è®¡åˆ’éªŒè¯å¤±è´¥",
                "error_detail": error_msg,
                "tool_plan": tool_plan,
                "llm_response": second_response
            }
        
        logger.info(f"Worké˜¶æ®µ - æˆåŠŸç”Ÿæˆå¹¶éªŒè¯å·¥å…·è°ƒç”¨è®¡åˆ’")
        if "sub_plans" in tool_plan:
            logger.info(f"Worké˜¶æ®µ - å¤šä»»åŠ¡æ¨¡å¼ï¼Œå­è®¡åˆ’æ•°: {len(tool_plan.get('sub_plans', []))}")
        else:
            steps = tool_plan.get('steps', [])
            logger.info(f"Worké˜¶æ®µ - å•ä»»åŠ¡æ¨¡å¼ï¼Œæ­¥éª¤æ•°: {len(steps)}")
        
        # ä¿å­˜ç¬¬ä¸€è½®å’Œç¬¬äºŒè½®LLMå“åº”ï¼Œä¾›å‰ç«¯å±•ç¤º
        tool_plan["first_llm_response"] = first_response
        tool_plan["second_llm_response"] = second_response
        
        return tool_plan
    
    def _validate_tool_plan(self, plan: Dict) -> Dict[str, Any]:
        """
        éªŒè¯å·¥å…·è°ƒç”¨è®¡åˆ’çš„æœ‰æ•ˆæ€§
        
        Args:
            plan: å·¥å…·è°ƒç”¨è®¡åˆ’å­—å…¸
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸ {"valid": bool, "error": str}
        """
        valid_tool_types = ["buffer", "elevation", "slope", "vegetation", "relative_position", "distance", "area"]
        required_params = {
            "buffer": ["buffer_distance"],
            "relative_position": ["reference_point", "reference_direction", "position_types"]
        }
        
        def validate_step(step: Dict, step_index: int = None) -> Tuple[bool, str]:
            """éªŒè¯å•ä¸ªæ­¥éª¤"""
            if not isinstance(step, dict):
                return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}å¿…é¡»æ˜¯å­—å…¸ç±»å‹"
            
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if "type" not in step:
                return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}ç¼ºå°‘typeå­—æ®µ"
            
            step_type = step.get("type")
            if step_type not in valid_tool_types:
                return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}çš„type '{step_type}'æ— æ•ˆï¼Œå¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€: {', '.join(valid_tool_types)}"
            
            # æ£€æŸ¥paramså­—æ®µ
            if "params" not in step:
                return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}ç¼ºå°‘paramså­—æ®µ"
            
            params = step.get("params", {})
            if not isinstance(params, dict):
                return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}çš„paramså¿…é¡»æ˜¯å­—å…¸ç±»å‹"
            
            # æ£€æŸ¥å¿…éœ€å‚æ•°
            if step_type in required_params:
                missing_params = []
                for req_param in required_params[step_type]:
                    if req_param not in params or params[req_param] is None:
                        missing_params.append(req_param)
                
                if missing_params:
                    return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}çš„type '{step_type}'ç¼ºå°‘å¿…éœ€å‚æ•°: {', '.join(missing_params)}"
            
            # ç‰¹æ®ŠéªŒè¯ï¼šrelative_positionçš„reference_pointæ ¼å¼
            if step_type == "relative_position":
                ref_point = params.get("reference_point")
                if not isinstance(ref_point, dict):
                    return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}çš„reference_pointå¿…é¡»æ˜¯å¯¹è±¡ç±»å‹ {{'lon': float, 'lat': float}}"
                
                if "lon" not in ref_point or "lat" not in ref_point:
                    return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}çš„reference_pointå¿…é¡»åŒ…å«lonå’Œlatå­—æ®µ"
                
                try:
                    float(ref_point["lon"])
                    float(ref_point["lat"])
                except (ValueError, TypeError):
                    return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}çš„reference_pointçš„lonå’Œlatå¿…é¡»æ˜¯æ•°å­—ç±»å‹"
                
                ref_direction = params.get("reference_direction")
                if not isinstance(ref_direction, (int, float)):
                    return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}çš„reference_directionå¿…é¡»æ˜¯æ•°å­—ç±»å‹"
                
                position_types = params.get("position_types")
                if not isinstance(position_types, list):
                    return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}çš„position_typeså¿…é¡»æ˜¯æ•°ç»„ç±»å‹"
                
                if len(position_types) == 0:
                    return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}çš„position_typesæ•°ç»„ä¸èƒ½ä¸ºç©º"
            
            # ç‰¹æ®ŠéªŒè¯ï¼šbufferçš„buffer_distance
            if step_type == "buffer":
                buffer_distance = params.get("buffer_distance")
                if buffer_distance is None:
                    return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}çš„buffer_distanceä¸èƒ½ä¸ºç©º"
                if not isinstance(buffer_distance, (int, float)) or buffer_distance <= 0:
                    return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}çš„buffer_distanceå¿…é¡»æ˜¯æ­£æ•°"
            
            # éªŒè¯step_id
            if "step_id" not in step:
                return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}ç¼ºå°‘step_idå­—æ®µ"
            
            step_id = step.get("step_id")
            if not isinstance(step_id, int) or step_id <= 0:
                return False, f"æ­¥éª¤{step_index + 1 if step_index is not None else ''}çš„step_idå¿…é¡»æ˜¯æ­£æ•´æ•°"
            
            return True, ""
        
        # éªŒè¯å•ä»»åŠ¡æ¨¡å¼
        if "steps" in plan:
            steps = plan.get("steps", [])
            if not isinstance(steps, list):
                return {"valid": False, "error": "stepså­—æ®µå¿…é¡»æ˜¯æ•°ç»„ç±»å‹"}
            
            if len(steps) == 0:
                return {"valid": False, "error": "stepsæ•°ç»„ä¸èƒ½ä¸ºç©º"}
            
            for i, step in enumerate(steps):
                is_valid, error_msg = validate_step(step, i)
                if not is_valid:
                    return {"valid": False, "error": error_msg}
        
        # éªŒè¯å¤šä»»åŠ¡æ¨¡å¼
        elif "sub_plans" in plan:
            sub_plans = plan.get("sub_plans", [])
            if not isinstance(sub_plans, list):
                return {"valid": False, "error": "sub_planså­—æ®µå¿…é¡»æ˜¯æ•°ç»„ç±»å‹"}
            
            if len(sub_plans) == 0:
                return {"valid": False, "error": "sub_plansæ•°ç»„ä¸èƒ½ä¸ºç©º"}
            
            for sub_plan in sub_plans:
                if not isinstance(sub_plan, dict):
                    return {"valid": False, "error": "sub_plansä¸­çš„æ¯ä¸ªå…ƒç´ å¿…é¡»æ˜¯å­—å…¸ç±»å‹"}
                
                if "steps" not in sub_plan:
                    return {"valid": False, "error": "sub_planç¼ºå°‘stepså­—æ®µ"}
                
                sub_steps = sub_plan.get("steps", [])
                if not isinstance(sub_steps, list):
                    return {"valid": False, "error": "sub_plançš„stepså­—æ®µå¿…é¡»æ˜¯æ•°ç»„ç±»å‹"}
                
                if len(sub_steps) == 0:
                    return {"valid": False, "error": "sub_plançš„stepsæ•°ç»„ä¸èƒ½ä¸ºç©º"}
                
                for i, step in enumerate(sub_steps):
                    is_valid, error_msg = validate_step(step, i)
                    if not is_valid:
                        unit = sub_plan.get("unit", "æœªçŸ¥å•ä½")
                        return {"valid": False, "error": f"{unit}çš„å­è®¡åˆ’ä¸­: {error_msg}"}
        else:
            return {"valid": False, "error": "è®¡åˆ’å¿…é¡»åŒ…å«stepsæˆ–sub_planså­—æ®µ"}
        
        return {"valid": True}
    
    def _parse_first_think_response(self, response: str) -> Dict:
        """
        è§£æç¬¬ä¸€è½®æ€è€ƒçš„å“åº”ï¼ˆå·¥å…·é€‰æ‹©å’Œå‚æ•°ï¼‰
        
        Args:
            response: LLMå“åº”æ–‡æœ¬
            
        Returns:
            è§£æåçš„å·¥å…·é€‰æ‹©å’Œå‚æ•°å­—å…¸
        """
        # é¦–å…ˆå°è¯•ä»ä»£ç å—ä¸­æå–JSON
        json_block_match = re.search(r'```(?:json)?\s*(\{[\s\S]*?\})\s*```', response)
        if json_block_match:
            try:
                json_str = json_block_match.group(1)
                result = json.loads(json_str)
                if "tools" in result:
                    logger.info("æˆåŠŸä»JSONä»£ç å—è§£æç¬¬ä¸€è½®æ€è€ƒç»“æœ")
                    return result
            except json.JSONDecodeError as e:
                logger.error(f"è§£æJSONä»£ç å—å¤±è´¥: {e}")
        
        # å°è¯•ä»æ–‡æœ¬ä¸­æå–JSONå¯¹è±¡
        json_match = None
        matches = list(re.finditer(r'\{[\s\S]*\}', response))
        for match in reversed(matches):
            try:
                json_str = match.group()
                test_json = json.loads(json_str)
                if "tools" in test_json:
                    json_match = match
                    break
            except:
                continue
        
        if json_match:
            try:
                json_str = json_match.group()
                result = json.loads(json_str)
                logger.info("æˆåŠŸä»æ–‡æœ¬ä¸­è§£æç¬¬ä¸€è½®æ€è€ƒç»“æœ")
                return result
            except json.JSONDecodeError as e:
                logger.error(f"è§£æJSONå¤±è´¥: {e}")
        
        return {
            "error": "æ— æ³•è§£æç¬¬ä¸€è½®æ€è€ƒç»“æœ",
            "response": response
        }
    
    def _execute_single_plan(self, plan: Dict) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä»»åŠ¡è®¡åˆ’"""
        print("\nå¼€å§‹æ‰§è¡Œè®¡åˆ’...")
        print("-" * 80)
        result = self._execute_steps(plan.get("steps", []), plan)
        if result.get("success"):
            print("\nâœ“ è®¡åˆ’æ‰§è¡ŒæˆåŠŸ")
        else:
            print(f"\nâœ— è®¡åˆ’æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        return result
    
    def _execute_sub_plans(self, plan: Dict) -> Dict[str, Any]:
        """æ‰§è¡Œå¤šä»»åŠ¡è®¡åˆ’"""
        sub_plans = plan.get("sub_plans", [])
        sub_results = []
        all_success = True

        for sub_plan in sub_plans:
            unit = sub_plan.get("unit", "æœªçŸ¥å•ä½")
            print(f"\næ‰§è¡Œå­è®¡åˆ’: {unit}")
            print("-" * 80)
            step_results = self._execute_steps(sub_plan.get("steps", []), sub_plan, unit=unit)
            
            if step_results.get("success"):
                print(f"âœ“ {unit} æ‰§è¡ŒæˆåŠŸ")
                sub_results.append({
                    "unit": unit,
                    "success": True,
                    "result_path": step_results.get("final_result_path"),
                    "steps": step_results.get("results", [])
                })
            else:
                all_success = False
                print(f"âœ— {unit} æ‰§è¡Œå¤±è´¥: {step_results.get('error', 'æœªçŸ¥é”™è¯¯')}")
                sub_results.append({
                    "unit": unit,
                    "success": False,
                    "error": step_results.get("error"),
                    "result_path": None,
                    "steps": step_results.get("results", [])
                })

        return {
            "success": all_success,
            "sub_results": sub_results,
            "plan": plan
        }
    
    def _execute_steps(self, steps: List[Dict], plan: Dict, unit: str = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ­¥éª¤åˆ—è¡¨ï¼ˆå…¬å…±é€»è¾‘ï¼‰
        
        Args:
            steps: æ­¥éª¤åˆ—è¡¨
            plan: è®¡åˆ’å­—å…¸
            unit: å•ä½åç§°ï¼ˆç”¨äºå¤šä»»åŠ¡æ¨¡å¼ï¼‰
            
        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        
        results = []
        last_result_path = None
        intermediate_geojson_paths = []  # è·Ÿè¸ªä¸­é—´æ­¥éª¤ä¿å­˜çš„geojsonæ–‡ä»¶
        initial_geojson_path = None  # è·Ÿè¸ªåˆå§‹GeoJSONæ–‡ä»¶è·¯å¾„

        # å¦‚æœç¬¬ä¸€ä¸ªå…è®¸çš„æ­¥éª¤éœ€è¦input_geojson_pathï¼Œå…ˆç”Ÿæˆåˆå§‹GeoJSON
        # éœ€è¦åˆå§‹GeoJSONçš„æ­¥éª¤ç±»å‹ï¼šrelative_position, distance, area
        allowed_tool_types = ["relative_position", "distance", "area"]
        first_allowed_step = None
        first_allowed_step_index = None
        for i, step in enumerate(steps):
            step_type = step.get("type", "")
            if step_type in allowed_tool_types:
                first_allowed_step = step
                first_allowed_step_index = i
                break
        
        needs_initial_geojson = first_allowed_step is not None and first_allowed_step.get("type") in ["relative_position", "distance", "area"]
        
        if needs_initial_geojson:
            try:
                first_step_params = first_allowed_step.get("params", {})
                utm_crs = first_step_params.get("utm_crs")
                initial_geojson_path = generate_initial_geojson(utm_crs=utm_crs)
                last_result_path = initial_geojson_path
                # æ³¨æ„ï¼šåˆå§‹GeoJSONæ–‡ä»¶ä¸ç«‹å³æ·»åŠ åˆ°å¾…æ¸…ç†åˆ—è¡¨ï¼Œè€Œæ˜¯åœ¨æ‰€æœ‰æ­¥éª¤å®Œæˆåæ‰åˆ é™¤
                # ç¡®ä¿ç¬¬ä¸€æ­¥çš„paramså­˜åœ¨
                if "params" not in first_allowed_step:
                    first_allowed_step["params"] = {}
                # å°†åˆå§‹GeoJSONè·¯å¾„å¡«å……åˆ°ç¬¬ä¸€ä¸ªå…è®¸æ­¥éª¤çš„paramsä¸­ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
                if "input_geojson_path" not in first_allowed_step["params"] or not first_allowed_step["params"]["input_geojson_path"]:
                    first_allowed_step["params"]["input_geojson_path"] = initial_geojson_path
                logger.info(f"ç”Ÿæˆåˆå§‹GeoJSONæ–‡ä»¶: {initial_geojson_path}")
            except Exception as e:
                logger.error(f"ç”Ÿæˆåˆå§‹GeoJSONå¤±è´¥: {e}")
                return {
                    "success": False,
                    "error": f"ç”Ÿæˆåˆå§‹GeoJSONå¤±è´¥: {str(e)}",
                    "results": results
                }

        # æ ¹æ®é…ç½®å†³å®šå…è®¸çš„å·¥å…·ç±»å‹
        # å·¥å…·ç±»å‹åˆ°å·¥å…·åç§°çš„æ˜ å°„
        type_to_tool_mapping = {
            "buffer": "buffer_filter_tool",
            "elevation": "elevation_filter_tool",
            "slope": "slope_filter_tool",
            "vegetation": "vegetation_filter_tool",
            "relative_position": "relative_position_filter_tool",
            "distance": "distance_filter_tool",
            "area": "area_filter_tool"
        }
        
        # æ ¹æ®TOOL_ENABLE_CONFIGç­›é€‰å…è®¸çš„å·¥å…·ç±»å‹
        allowed_tool_types = [
            tool_type for tool_type, tool_name in type_to_tool_mapping.items()
            if TOOL_ENABLE_CONFIG.get(tool_name, True)  # é»˜è®¤å¯ç”¨
        ]
        
        logger.info(f"å¯ç”¨çš„å·¥å…·ç±»å‹: {allowed_tool_types}")
        
        # æ‰¾åˆ°æœ€åä¸€ä¸ªå…è®¸çš„å·¥å…·ç±»å‹çš„ç´¢å¼•
        last_allowed_step_index = None
        for i in range(len(steps) - 1, -1, -1):
            step_type = steps[i].get("type", "")
            if step_type in allowed_tool_types:
                last_allowed_step_index = i
                break
        
        for i, step in enumerate(steps):
            step_type = step.get("type", "")
            
            # å¦‚æœå·¥å…·ç±»å‹ä¸åœ¨å…è®¸åˆ—è¡¨ä¸­ï¼Œè·³è¿‡è¯¥æ­¥éª¤
            if step_type and step_type not in allowed_tool_types:
                logger.info(f"è·³è¿‡å·¥å…·ç±»å‹ '{step_type}'ï¼ˆä¸åœ¨å…è®¸çš„å·¥å…·åˆ—è¡¨ä¸­ï¼‰")
                # è®°å½•è·³è¿‡çš„æ­¥éª¤
                results.append({
                    "success": True,
                    "tool": step_type,
                    "skipped": True,
                    "message": f"å·¥å…·ç±»å‹ '{step_type}' å·²è·³è¿‡ï¼ˆä¸åœ¨å…è®¸çš„å·¥å…·åˆ—è¡¨ä¸­ï¼‰"
                })
                continue
            
            # å‡†å¤‡é“¾å¼è°ƒç”¨çš„è¾“å…¥è·¯å¾„
            prepare_step_input_path(step, last_result_path, self.tools)

            try:
                step_result = self._execute_step(step)
                results.append(step_result)

                if step_result.get("success") and step_result.get("result", {}).get("result_path"):
                    result_path = step_result["result"]["result_path"]
                    # è®°å½•ä¸­é—´æ­¥éª¤çš„geojsonæ–‡ä»¶ï¼ˆé™¤äº†æœ€åä¸€ä¸ªå…è®¸çš„å·¥å…·ç±»å‹ï¼‰
                    if i != last_allowed_step_index:  # ä¸æ˜¯æœ€åä¸€ä¸ªå…è®¸çš„å·¥å…·ç±»å‹
                        intermediate_geojson_paths.append(result_path)
                    last_result_path = result_path

                if not step_result.get("success", False):
                    error_msg = f"æ‰§è¡Œæ­¥éª¤ {i+1} æ—¶å‡ºé”™"
                    if unit:
                        error_msg = f"æ‰§è¡Œ{unit}æ­¥éª¤ {i+1} æ—¶å‡ºé”™"
                    
                    # å¦‚æœå‡ºé”™ï¼Œæ¸…ç†å·²ä¿å­˜çš„ä¸­é—´æ–‡ä»¶ï¼ˆä¸åŒ…æ‹¬åˆå§‹GeoJSONï¼Œå› ä¸ºå®ƒå¯èƒ½è¿˜åœ¨è¢«ä½¿ç”¨ï¼‰
                    self._cleanup_intermediate_files(intermediate_geojson_paths)
                    # å¦‚æœåˆå§‹GeoJSONå­˜åœ¨ä¸”ä¸åœ¨ä¸­é—´æ–‡ä»¶åˆ—è¡¨ä¸­ï¼Œä¹Ÿåˆ é™¤å®ƒï¼ˆå› ä¸ºå·²ç»å¤±è´¥ï¼Œä¸ä¼šç»§ç»­ä½¿ç”¨ï¼‰
                    if initial_geojson_path:
                        self._cleanup_intermediate_files([initial_geojson_path])
                    
                    return {
                        "success": False,
                        "error": step_result.get("error") or error_msg,
                        "completed_steps": results,
                        "results": results
                    }
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                error_msg = f"æ‰§è¡Œæ­¥éª¤ {i+1} æ—¶å‡ºé”™: {str(e)}"
                if unit:
                    error_msg = f"æ‰§è¡Œ{unit}æ­¥éª¤ {i+1} æ—¶å‡ºé”™: {str(e)}"
                
                logger.error(error_msg)
                logger.error(error_detail)
                
                # å¦‚æœå‡ºé”™ï¼Œæ¸…ç†å·²ä¿å­˜çš„ä¸­é—´æ–‡ä»¶ï¼ˆä¸åŒ…æ‹¬åˆå§‹GeoJSONï¼Œå› ä¸ºå®ƒå¯èƒ½è¿˜åœ¨è¢«ä½¿ç”¨ï¼‰
                self._cleanup_intermediate_files(intermediate_geojson_paths)
                # å¦‚æœåˆå§‹GeoJSONå­˜åœ¨ä¸”ä¸åœ¨ä¸­é—´æ–‡ä»¶åˆ—è¡¨ä¸­ï¼Œä¹Ÿåˆ é™¤å®ƒï¼ˆå› ä¸ºå·²ç»å¤±è´¥ï¼Œä¸ä¼šç»§ç»­ä½¿ç”¨ï¼‰
                if initial_geojson_path:
                    self._cleanup_intermediate_files([initial_geojson_path])
                
                return {
                    "success": False,
                    "error": error_msg,
                    "completed_steps": results,
                    "results": results
                }

        # æ‰€æœ‰æ­¥éª¤æ‰§è¡ŒæˆåŠŸï¼Œåˆ é™¤ä¸­é—´æ­¥éª¤ä¿å­˜çš„geojsonæ–‡ä»¶
        self._cleanup_intermediate_files(intermediate_geojson_paths)
        # åˆ é™¤åˆå§‹GeoJSONæ–‡ä»¶ï¼ˆæ‰€æœ‰æ­¥éª¤å·²å®Œæˆï¼Œä¸å†éœ€è¦ï¼‰
        if initial_geojson_path:
            self._cleanup_intermediate_files([initial_geojson_path])

        # å¦‚æœæ‰§è¡ŒæˆåŠŸä¸”æœ‰æœ€ç»ˆç»“æœè·¯å¾„ï¼Œä¿å­˜metadataæ–‡ä»¶
        if last_result_path:
            try:
                self._save_result_metadata(last_result_path, plan, results, unit)
            except Exception as e:
                logger.warning(f"ä¿å­˜ç»“æœmetadataå¤±è´¥: {e}", exc_info=True)
        
        return {
            "success": True,
            "results": results,
            "plan": plan,
            "final_result_path": last_result_path
        }
    
    def _cleanup_intermediate_files(self, file_paths: List[str]):
        """
        åˆ é™¤ä¸­é—´æ­¥éª¤ä¿å­˜çš„geojsonæ–‡ä»¶
        
        Args:
            file_paths: è¦åˆ é™¤çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        from pathlib import Path
        import os
        
        for file_path in file_paths:
            if file_path:
                try:
                    path = Path(file_path)
                    if path.exists() and path.is_file():
                        os.remove(file_path)
                        logger.info(f"å·²åˆ é™¤ä¸­é—´æ­¥éª¤æ–‡ä»¶: {file_path}")
                except Exception as e:
                    logger.warning(f"åˆ é™¤ä¸­é—´æ­¥éª¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

    def _prepare_step_params(self, step_type: str, params: Dict) -> Dict:
        """
        å‡†å¤‡æ­¥éª¤å‚æ•°ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
        
        Args:
            step_type: æ­¥éª¤ç±»å‹
            params: åŸå§‹å‚æ•°å­—å…¸
            
        Returns:
            å¤„ç†åçš„å‚æ•°å­—å…¸ï¼Œå¦‚æœå‡ºé”™è¿”å›åŒ…å«erroré”®çš„å­—å…¸
        """
        prepared_params = params.copy()
        
        # input_geojson_pathç”±ç³»ç»Ÿè‡ªåŠ¨ç®¡ç†ï¼Œä¸éœ€è¦éªŒè¯æˆ–å¤„ç†
        # å®ƒä¼šåœ¨_execute_stepsä¸­è‡ªåŠ¨å¡«å……
        
        # é’ˆå¯¹relative_positionçš„ç‰¹æ®Šå¤„ç†
        if step_type == "relative_position":
            # ç¡®ä¿reference_pointæ˜¯å­—å…¸æ ¼å¼
            if "reference_point" in prepared_params:
                ref_point = prepared_params["reference_point"]
                if isinstance(ref_point, dict):
                    # ç¡®ä¿lonå’Œlatæ˜¯floatç±»å‹
                    if "lon" in ref_point:
                        try:
                            prepared_params["reference_point"]["lon"] = float(ref_point["lon"])
                        except (ValueError, TypeError):
                            return {"error": f"reference_point.lonå¿…é¡»æ˜¯æ•°å­—ç±»å‹ï¼Œå½“å‰å€¼: {ref_point.get('lon')}"}
                    if "lat" in ref_point:
                        try:
                            prepared_params["reference_point"]["lat"] = float(ref_point["lat"])
                        except (ValueError, TypeError):
                            return {"error": f"reference_point.latå¿…é¡»æ˜¯æ•°å­—ç±»å‹ï¼Œå½“å‰å€¼: {ref_point.get('lat')}"}
                else:
                    return {"error": f"reference_pointå¿…é¡»æ˜¯å¯¹è±¡ç±»å‹ï¼Œå½“å‰ç±»å‹: {type(ref_point).__name__}"}
            
            # ç¡®ä¿reference_directionæ˜¯æ•°å­—
            if "reference_direction" in prepared_params:
                try:
                    prepared_params["reference_direction"] = float(prepared_params["reference_direction"])
                except (ValueError, TypeError):
                    return {"error": f"reference_directionå¿…é¡»æ˜¯æ•°å­—ç±»å‹ï¼Œå½“å‰å€¼: {prepared_params.get('reference_direction')}"}
            
            # ç¡®ä¿position_typesæ˜¯åˆ—è¡¨
            if "position_types" in prepared_params:
                if not isinstance(prepared_params["position_types"], list):
                    return {"error": f"position_typeså¿…é¡»æ˜¯æ•°ç»„ç±»å‹ï¼Œå½“å‰ç±»å‹: {type(prepared_params['position_types']).__name__}"}
        
        # é’ˆå¯¹bufferçš„ç‰¹æ®Šå¤„ç†
        if step_type == "buffer":
            if "buffer_distance" in prepared_params:
                try:
                    prepared_params["buffer_distance"] = float(prepared_params["buffer_distance"])
                    if prepared_params["buffer_distance"] <= 0:
                        return {"error": f"buffer_distanceå¿…é¡»æ˜¯æ­£æ•°ï¼Œå½“å‰å€¼: {prepared_params['buffer_distance']}"}
                except (ValueError, TypeError):
                    return {"error": f"buffer_distanceå¿…é¡»æ˜¯æ•°å­—ç±»å‹ï¼Œå½“å‰å€¼: {prepared_params.get('buffer_distance')}"}
        
        return prepared_params
    
    def _execute_step(self, step: Dict) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
        step_type = step.get("type", "")
        step_params = step.get("params", {})

        type_to_tool = {
            "buffer": "buffer_filter_tool",
            "elevation": "elevation_filter_tool",
            "slope": "slope_filter_tool",
            "vegetation": "vegetation_filter_tool",
            "relative_position": "relative_position_filter_tool",
            "distance": "distance_filter_tool",
            "area": "area_filter_tool"
        }

        # å¦‚æœstepä¸­ç›´æ¥æŒ‡å®šäº†toolï¼Œä½¿ç”¨å®ƒ
        if step.get("tool"):
            result = self._act({
                "tool": step["tool"],
                "params": step_params
            })
            # å¦‚æœæ­¥éª¤æ ‡è®°ä¸ºä½¿ç”¨é»˜è®¤å€¼ï¼Œå°†æ ‡è®°ä¼ é€’åˆ°ç»“æœä¸­
            if step.get("is_default"):
                result["is_default"] = True
            return result

        # å¦‚æœstepæœ‰typeï¼Œæ˜ å°„åˆ°å¯¹åº”çš„å·¥å…·
        if step_type and step_type in type_to_tool:
            tool_name = type_to_tool[step_type]
            
            # æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨
            if tool_name not in self.tools:
                return {
                    "success": False,
                    "error": f"å·¥å…· '{tool_name}' æœªå¯ç”¨ï¼ˆåœ¨config.pyçš„TOOL_ENABLE_CONFIGä¸­è®¾ç½®ä¸ºFalseï¼‰"
                }
            
            # å†æ¬¡éªŒè¯å‚æ•°ï¼ˆåœ¨å·¥å…·è°ƒç”¨å‰è¿›è¡Œæœ€åçš„å‚æ•°æ ¼å¼æ£€æŸ¥ï¼‰
            if not step_params:
                return {
                    "success": False,
                    "error": f"æ­¥éª¤ {step_type} ç¼ºå°‘å¿…éœ€å‚æ•°ï¼Œè®¡åˆ’ä¸­çš„paramsä¸ºç©ºã€‚è¯·é‡æ–°ç”ŸæˆåŒ…å«å…·ä½“å‚æ•°çš„è®¡åˆ’ã€‚"
                }
            
            # ç¡®ä¿paramsä¸­çš„å‚æ•°æ ¼å¼æ­£ç¡®ï¼ˆç‰¹åˆ«æ˜¯å¤æ‚å¯¹è±¡ï¼‰
            validated_params = self._prepare_step_params(step_type, step_params)
            if "error" in validated_params:
                return {
                    "success": False,
                    "error": validated_params["error"]
                }
            
            result = self._act({
                "tool": tool_name,
                "params": validated_params
            })
            # å¦‚æœæ­¥éª¤æ ‡è®°ä¸ºä½¿ç”¨é»˜è®¤å€¼ï¼Œå°†æ ‡è®°ä¼ é€’åˆ°ç»“æœä¸­
            if step.get("is_default"):
                result["is_default"] = True
            return result

        # å¦‚æœæ—¢æ²¡æœ‰toolä¹Ÿæ²¡æœ‰typeï¼Œè¿”å›é”™è¯¯
        return {
            "success": False,
            "error": f"æ­¥éª¤ç¼ºå°‘typeæˆ–toolå­—æ®µï¼Œæ— æ³•ç¡®å®šæ‰§è¡ŒåŠ¨ä½œã€‚æ­¥éª¤: {step}"
        }

    def _act(self, action: Dict) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        tool_name = action.get("tool")
        if tool_name not in self.tools:
            return {
                "success": False,
                "error": f"å·¥å…·ä¸å­˜åœ¨: {tool_name}"
            }

        tool = self.tools[tool_name]
        params = action.get("params", {})

        if not tool.validate_params(**params):
            # è®°å½•è¯¦ç»†çš„å‚æ•°ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
            logger.error(f"å·¥å…· {tool_name} å‚æ•°éªŒè¯å¤±è´¥ï¼Œå‚æ•°: {params}")
            return {
                "success": False,
                "error": f"å‚æ•°éªŒè¯å¤±è´¥: å·¥å…· {tool_name} çš„å‚æ•°ä¸æ»¡è¶³è¦æ±‚ã€‚å‚æ•°: {params}"
            }

        try:
            result = tool.execute(**params)

            is_success = result.get("success", False)

            return {
                "success": is_success,
                "tool": tool_name,
                "params": params,
                "result": result,
                "error": result.get("error") if not is_success else None
            }
        except Exception as e:
            error_msg = str(e)
            logger.error(f"å·¥å…· {tool_name} æ‰§è¡Œå¼‚å¸¸: {error_msg}", exc_info=True)
            return {
                "success": False,
                "error": error_msg
            }
    
    def _save_result_metadata(self, result_path: str, plan: Dict, step_results: List[Dict], unit: str = None):
        """
        ä¿å­˜ç»“æœæ–‡ä»¶åˆ°ä¸åŒçš„æ–‡ä»¶å¤¹ï¼š
        - geojson: ç»“æœGeoJSONæ–‡ä»¶ï¼ˆå·²ç”±å·¥å…·ä¿å­˜ï¼‰
        - regions: åŒºåŸŸä¿¡æ¯JSONæ–‡ä»¶
        - llm_thinking: LLMæ€è€ƒç»“æœJSONæ–‡ä»¶
        - kg_graph: å®ä½“å…³ç³»å›¾JSONæ–‡ä»¶
        
        Args:
            result_path: GeoJSONç»“æœæ–‡ä»¶è·¯å¾„
            plan: è®¡åˆ’å­—å…¸ï¼ˆåŒ…å«kag_resultsç­‰ä¿¡æ¯ï¼‰
            step_results: æ­¥éª¤æ‰§è¡Œç»“æœåˆ—è¡¨
            unit: å•ä½åç§°ï¼ˆç”¨äºå¤šä»»åŠ¡æ¨¡å¼ï¼‰
        """
        try:
            from config import PATHS
            import json
            
            result_file = Path(result_path)
            if not result_file.exists():
                logger.warning(f"ç»“æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•ä¿å­˜metadata: {result_path}")
                return
            
            # è·å–åŸºç¡€æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            base_name = result_file.stem
            
            # ç¡®ä¿å„ä¸ªæ–‡ä»¶å¤¹å­˜åœ¨
            regions_dir = PATHS["result_regions_dir"]
            llm_thinking_dir = PATHS["result_llm_thinking_dir"]
            kg_graph_dir = PATHS["result_kg_graph_dir"]
            
            regions_dir.mkdir(parents=True, exist_ok=True)
            llm_thinking_dir.mkdir(parents=True, exist_ok=True)
            kg_graph_dir.mkdir(parents=True, exist_ok=True)
            
            # æå–åŒºåŸŸä¿¡æ¯ï¼ˆä»planæˆ–session_stateä¸­è·å–ï¼Œè¿™é‡Œå…ˆå°è¯•ä»planä¸­è§£æï¼‰
            regions = []
            original_query = plan.get("original_query", "")
            if original_query:
                # å°è¯•ä»æŸ¥è¯¢ä¸­è§£æåŒºåŸŸä¿¡æ¯
                try:
                    regions = self._parse_regions_from_task(original_query)
                except:
                    pass
            
            # æå–å‚è€ƒç‚¹ä¿¡æ¯ï¼ˆä»step_resultsä¸­æå–ï¼‰
            reference_points = []
            for step_result in step_results:
                if step_result.get("success") and step_result.get("tool") == "relative_position_filter_tool":
                    step_params = step_result.get("params", {})
                    result_data = step_result.get("result", {})
                    # ä¼˜å…ˆä½¿ç”¨ç»“æœä¸­çš„å‚è€ƒç‚¹ä¿¡æ¯
                    ref_point = None
                    ref_dir = None
                    if result_data.get("reference_point"):
                        ref_point = result_data.get("reference_point")
                    elif step_params.get("reference_point"):
                        ref_point = step_params.get("reference_point")
                    if result_data.get("reference_direction") is not None:
                        ref_dir = result_data.get("reference_direction")
                    elif step_params.get("reference_direction") is not None:
                        ref_dir = step_params.get("reference_direction")
                    
                    if ref_point and ref_dir is not None:
                        reference_points.append({
                            "point": ref_point,
                            "direction": ref_dir
                        })
            
            # æå–KAGé—®ç­”ç»“æœ
            kag_results = plan.get("kag_results", [])
            kag_qa_results = []
            for kag_result in kag_results:
                kag_qa_results.append({
                    "question": kag_result.get("question", ""),
                    "answer": kag_result.get("answer", ""),
                    "input_query": kag_result.get("input_query", "")
                })
            
            # ä¼˜å…ˆä½¿ç”¨planä¸­å·²æœ‰çš„retrieved_entitieså’Œretrieved_relations
            retrieved_entities = plan.get("retrieved_entities", [])
            retrieved_relations = plan.get("retrieved_relations", [])
            
            logger.info(f"ä»planä¸­è·å–çš„å®ä½“æ•°é‡: {len(retrieved_entities)}, å…³ç³»æ•°é‡: {len(retrieved_relations)}")
            
            # å¦‚æœplanä¸­æ²¡æœ‰ï¼Œåˆ™ä»kag_resultsçš„tasksä¸­æå–æ£€ç´¢åˆ°çš„å®ä½“å’Œå…³ç³»ï¼ˆå‘åå…¼å®¹ï¼‰
            if not retrieved_entities and not retrieved_relations:
                logger.info("planä¸­æ²¡æœ‰retrieved_entitieså’Œretrieved_relationsï¼Œå°è¯•ä»kag_resultsä¸­æå–")
                entity_id_set = set()  # ç”¨äºå»é‡
                relation_key_set = set()  # ç”¨äºå»é‡
                
                # ä»kag_resultsçš„tasksä¸­æå–æ£€ç´¢åˆ°çš„å®ä½“å’Œå…³ç³»
                for kag_result in kag_results:
                    tasks = kag_result.get("tasks", [])
                    for task in tasks:
                        # ä»taskçš„memoryä¸­æå–
                        task_memory = task.get("memory", {})
                        if isinstance(task_memory, dict):
                            # ä»retrieverç»“æœä¸­æå–å®ä½“å’Œå…³ç³»
                            if "retriever" in task_memory:
                                retriever_output = task_memory["retriever"]
                                self._extract_entities_relations_from_retriever_output(
                                    retriever_output, retrieved_entities, retrieved_relations, entity_id_set, relation_key_set
                                )
                            
                            # ä»graph_dataä¸­æå–
                            if "graph_data" in task_memory:
                                graph_data = task_memory["graph_data"]
                                self._extract_entities_relations_from_graph_data(
                                    graph_data, retrieved_entities, retrieved_relations, entity_id_set, relation_key_set
                                )
                        
                        # ä»taskçš„resultä¸­æå–
                        task_result = task.get("result")
                        if task_result:
                            self._extract_entities_relations_from_retriever_output(
                                task_result, retrieved_entities, retrieved_relations, entity_id_set, relation_key_set
                            )
            
            # æå–ç­›é€‰å‚æ•°ä¿¡æ¯ï¼ˆä»step_resultsä¸­æå–ï¼‰
            filter_params_list = []
            for step_idx, step_result in enumerate(step_results):
                if step_result.get("success"):
                    tool_name = step_result.get("tool", "")
                    step_params = step_result.get("params", {})
                    is_default = step_result.get("is_default", False)
                    
                    # è·³è¿‡ä½¿ç”¨é»˜è®¤å€¼çš„å·¥å…·
                    if is_default:
                        continue
                    
                    # ä¸ºæ¯ä¸ªå·¥å…·è°ƒç”¨åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„å‚æ•°å­—å…¸
                    step_filter_params = {}
                    
                    if tool_name == "buffer_filter_tool":
                        buffer_dist = step_params.get("buffer_distance")
                        if buffer_dist is not None:
                            step_filter_params["ç¼“å†²åŒºè·ç¦»"] = f"{buffer_dist} ç±³"
                    elif tool_name == "elevation_filter_tool":
                        min_elev = step_params.get("min_elev")
                        max_elev = step_params.get("max_elev")
                        if min_elev is not None or max_elev is not None:
                            elev_str = ""
                            if min_elev is not None:
                                elev_str += f"{min_elev} ç±³"
                            if max_elev is not None:
                                if elev_str:
                                    elev_str += " - "
                                elev_str += f"{max_elev} ç±³"
                            step_filter_params["é«˜ç¨‹èŒƒå›´"] = elev_str
                    elif tool_name == "slope_filter_tool":
                        min_slope = step_params.get("min_slope")
                        max_slope = step_params.get("max_slope")
                        if min_slope is not None or max_slope is not None:
                            slope_str = ""
                            if min_slope is not None:
                                slope_str += f"{min_slope}Â°"
                            if max_slope is not None:
                                if slope_str:
                                    slope_str += " - "
                                slope_str += f"{max_slope}Â°"
                            step_filter_params["å¡åº¦èŒƒå›´"] = slope_str
                    elif tool_name == "vegetation_filter_tool":
                        veg_types = step_params.get("vegetation_types", [])
                        exclude_types = step_params.get("exclude_types", [])
                        if veg_types:
                            veg_names = {
                                10: "æ ‘", 20: "çŒæœ¨", 30: "è‰åœ°", 40: "è€•åœ°",
                                50: "å»ºç­‘", 60: "è£¸åœ°/ç¨€ç–æ¤è¢«", 70: "é›ªå’Œå†°",
                                80: "æ°´ä½“", 90: "æ¹¿åœ°", 95: "è‹”åŸ", 100: "æ°¸ä¹…æ€§æ°´ä½“"
                            }
                            veg_list = [veg_names.get(v, str(v)) for v in veg_types]
                            step_filter_params["æ¤è¢«ç±»å‹"] = ", ".join(veg_list)
                        elif exclude_types:
                            veg_names = {
                                10: "æ ‘", 20: "çŒæœ¨", 30: "è‰åœ°", 40: "è€•åœ°",
                                50: "å»ºç­‘", 60: "è£¸åœ°/ç¨€ç–æ¤è¢«", 70: "é›ªå’Œå†°",
                                80: "æ°´ä½“", 90: "æ¹¿åœ°", 95: "è‹”åŸ", 100: "æ°¸ä¹…æ€§æ°´ä½“"
                            }
                            exclude_list = [veg_names.get(v, str(v)) for v in exclude_types]
                            step_filter_params["æ’é™¤æ¤è¢«ç±»å‹"] = ", ".join(exclude_list)
                    elif tool_name == "relative_position_filter_tool":
                        reference_point = step_params.get("reference_point", {})
                        reference_direction = step_params.get("reference_direction")
                        position_types = step_params.get("position_types", [])
                        if reference_point:
                            lon = reference_point.get("lon")
                            lat = reference_point.get("lat")
                            if lon is not None and lat is not None:
                                step_filter_params["å‚è€ƒç‚¹åæ ‡"] = f"({lon:.6f}, {lat:.6f})"
                        if reference_direction is not None:
                            step_filter_params["å‚è€ƒæ–¹å‘"] = f"{reference_direction}Â°"
                        if position_types:
                            step_filter_params["ç›¸å¯¹ä½ç½®ç±»å‹"] = ", ".join(position_types)
                    elif tool_name == "distance_filter_tool":
                        reference_point = step_params.get("reference_point", {})
                        max_distance = step_params.get("max_distance")
                        if reference_point:
                            lon = reference_point.get("lon")
                            lat = reference_point.get("lat")
                            if lon is not None and lat is not None:
                                step_filter_params["å‚è€ƒç‚¹åæ ‡"] = f"({lon:.6f}, {lat:.6f})"
                        if max_distance is not None:
                            step_filter_params["æœ€å¤§è·ç¦»"] = f"{max_distance} ç±³"
                    elif tool_name == "area_filter_tool":
                        min_area_km2 = step_params.get("min_area_km2")
                        if min_area_km2 is not None:
                            step_filter_params["æœ€å°é¢ç§¯"] = f"{min_area_km2} å¹³æ–¹å…¬é‡Œ"
                    
                    # å¦‚æœæœ‰å‚æ•°ï¼Œæ·»åŠ åˆ°åˆ—è¡¨
                    if step_filter_params:
                        filter_params_list.append({
                            "step": step_idx + 1,
                            "tool": tool_name,
                            "params": step_filter_params
                        })
            
            # 1. ä¿å­˜åŒºåŸŸä¿¡æ¯åˆ°regionsæ–‡ä»¶å¤¹
            regions_data = {
                "result_file": result_file.name,
                "timestamp": datetime.now().isoformat(),
                "unit": unit,
                "original_query": original_query,
                "regions": regions,
                "reference_points": reference_points,
                "filter_params": filter_params_list
            }
            regions_path = regions_dir / f"{base_name}.json"
            with open(regions_path, "w", encoding="utf-8") as f:
                json.dump(regions_data, f, ensure_ascii=False, indent=2)
            logger.info(f"å·²ä¿å­˜åŒºåŸŸä¿¡æ¯: {regions_path}")
            
            # 2. ä¿å­˜LLMæ€è€ƒç»“æœåˆ°llm_thinkingæ–‡ä»¶å¤¹
            llm_thinking_data = {
                "result_file": result_file.name,
                "timestamp": datetime.now().isoformat(),
                "unit": unit,
                "original_query": original_query,
                "first_llm_response": plan.get("first_llm_response", ""),
                "second_llm_response": plan.get("second_llm_response", ""),
                "kag_qa_results": kag_qa_results
            }
            llm_thinking_path = llm_thinking_dir / f"{base_name}.json"
            with open(llm_thinking_path, "w", encoding="utf-8") as f:
                json.dump(llm_thinking_data, f, ensure_ascii=False, indent=2)
            logger.info(f"å·²ä¿å­˜LLMæ€è€ƒç»“æœ: {llm_thinking_path}")
            
            # 3. ä¿å­˜å®ä½“å…³ç³»å›¾åˆ°kg_graphæ–‡ä»¶å¤¹
            kg_graph_data = {
                "result_file": result_file.name,
                "timestamp": datetime.now().isoformat(),
                "unit": unit,
                "original_query": original_query,
                "retrieved_entities": retrieved_entities,
                "retrieved_relations": retrieved_relations
            }
            kg_graph_path = kg_graph_dir / f"{base_name}.json"
            with open(kg_graph_path, "w", encoding="utf-8") as f:
                json.dump(kg_graph_data, f, ensure_ascii=False, indent=2)
            logger.info(f"å·²ä¿å­˜å®ä½“å…³ç³»å›¾: {kg_graph_path}")
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœmetadataå¤±è´¥: {e}", exc_info=True)
    
    def _extract_entities_relations_from_retriever_output(self, retriever_output, retrieved_entities, retrieved_relations, entity_id_set, relation_key_set):
        """ä»retrieverè¾“å‡ºä¸­æå–å®ä½“å’Œå…³ç³»"""
        if isinstance(retriever_output, dict):
            # æ£€æŸ¥æ˜¯å¦æœ‰graph_dataæˆ–kg_graph
            graph_data = retriever_output.get("graph_data") or retriever_output.get("kg_graph")
            if graph_data:
                self._extract_entities_relations_from_graph_data(
                    graph_data, retrieved_entities, retrieved_relations, entity_id_set, relation_key_set
                )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰chunksï¼Œä»chunksä¸­æå–å®ä½“å’Œå…³ç³»
            chunks = retriever_output.get("chunks", [])
            for chunk in chunks:
                if isinstance(chunk, dict):
                    # å°è¯•ä»chunkçš„metadataä¸­æå–å®ä½“å’Œå…³ç³»
                    chunk_metadata = chunk.get("metadata", {})
                    if chunk_metadata:
                        # æ£€æŸ¥æ˜¯å¦æœ‰å®ä½“å’Œå…³ç³»ä¿¡æ¯
                        entities = chunk_metadata.get("entities", [])
                        relations = chunk_metadata.get("relations", [])
                        if entities:
                            for entity in entities:
                                if isinstance(entity, dict):
                                    entity_id = entity.get("id") or entity.get("name", "")
                                    if entity_id and entity_id not in entity_id_set:
                                        entity_id_set.add(entity_id)
                                        retrieved_entities.append({
                                            "id": entity_id,
                                            "name": entity.get("name", entity_id),
                                            "type": entity.get("type") or entity.get("label", "Unknown"),
                                            "properties": entity.get("properties", {})
                                        })
                        if relations:
                            for relation in relations:
                                if isinstance(relation, dict):
                                    source = relation.get("source") or relation.get("from_id") or relation.get("from", "")
                                    target = relation.get("target") or relation.get("to_id") or relation.get("to", "")
                                    relation_type = relation.get("type") or relation.get("label", "Unknown")
                                    if source and target:
                                        relation_key = f"{source}->{target}->{relation_type}"
                                        if relation_key not in relation_key_set:
                                            relation_key_set.add(relation_key)
                                            retrieved_relations.append({
                                                "source": source,
                                                "target": target,
                                                "type": relation_type,
                                                "properties": relation.get("properties", {})
                                            })
    
    def _extract_entities_relations_from_graph_data(self, graph_data, retrieved_entities, retrieved_relations, entity_id_set, relation_key_set):
        """ä»graph_dataä¸­æå–å®ä½“å’Œå…³ç³»"""
        if isinstance(graph_data, dict):
            # æå–èŠ‚ç‚¹ï¼ˆå®ä½“ï¼‰
            nodes = graph_data.get("nodes", graph_data.get("resultNodes", []))
            if not nodes and "result_nodes" in graph_data:
                nodes = graph_data.get("result_nodes", [])
            
            for node in nodes:
                if isinstance(node, dict):
                    entity_id = node.get("id") or node.get("name", "")
                    if entity_id and entity_id not in entity_id_set:
                        entity_id_set.add(entity_id)
                        retrieved_entities.append({
                            "id": entity_id,
                            "name": node.get("name", entity_id),
                            "type": node.get("type") or node.get("label", "Unknown"),
                            "properties": node.get("properties", {})
                        })
            
            # æå–è¾¹ï¼ˆå…³ç³»ï¼‰
            edges = graph_data.get("edges", graph_data.get("resultEdges", []))
            if not edges and "result_edges" in graph_data:
                edges = graph_data.get("result_edges", [])
            
            for edge in edges:
                if isinstance(edge, dict):
                    source = edge.get("from_id") or edge.get("from") or edge.get("source", "")
                    target = edge.get("to_id") or edge.get("to") or edge.get("target", "")
                    relation_type = edge.get("label") or edge.get("type", "Unknown")
                    if source and target:
                        relation_key = f"{source}->{target}->{relation_type}"
                        if relation_key not in relation_key_set:
                            relation_key_set.add(relation_key)
                            retrieved_relations.append({
                                "source": source,
                                "target": target,
                                "type": relation_type,
                                "properties": edge.get("properties", {})
                            })
        elif hasattr(graph_data, "result_nodes") and hasattr(graph_data, "result_edges"):
            # å¦‚æœæ˜¯KgGraphå¯¹è±¡ï¼Œå°è¯•è½¬æ¢ä¸ºå­—å…¸
            try:
                if hasattr(graph_data, "to_dict"):
                    graph_dict = graph_data.to_dict()
                    self._extract_entities_relations_from_graph_data(
                        graph_dict, retrieved_entities, retrieved_relations, entity_id_set, relation_key_set
                    )
                else:
                    # ç›´æ¥ä»å¯¹è±¡å±æ€§æå–
                    nodes = getattr(graph_data, "result_nodes", [])
                    edges = getattr(graph_data, "result_edges", [])
                    for node in nodes:
                        if hasattr(node, "id"):
                            entity_id = getattr(node, "id", "")
                            if entity_id and entity_id not in entity_id_set:
                                entity_id_set.add(entity_id)
                                retrieved_entities.append({
                                    "id": entity_id,
                                    "name": getattr(node, "name", entity_id),
                                    "type": getattr(node, "label", "Unknown"),
                                    "properties": getattr(node, "properties", {}) if hasattr(node, "properties") else {}
                                })
                    for edge in edges:
                        if hasattr(edge, "from_id") or hasattr(edge, "_from"):
                            source = getattr(edge, "from_id", "") or getattr(edge, "_from", "")
                            target = getattr(edge, "to_id", "") or getattr(edge, "to", "")
                            relation_type = getattr(edge, "label", "Unknown")
                            if source and target:
                                relation_key = f"{source}->{target}->{relation_type}"
                                if relation_key not in relation_key_set:
                                    relation_key_set.add(relation_key)
                                    retrieved_relations.append({
                                        "source": source,
                                        "target": target,
                                        "type": relation_type,
                                        "properties": getattr(edge, "properties", {}) if hasattr(edge, "properties") else {}
                                    })
            except Exception as e:
                logger.debug(f"ä»graph_dataå¯¹è±¡æå–å®ä½“å’Œå…³ç³»å¤±è´¥: {e}")
    
    def _parse_regions_from_task(self, task_text: str) -> List[Dict]:
        """
        ä»ä»»åŠ¡æ–‡æœ¬ä¸­è§£æåŒºåŸŸä¿¡æ¯ï¼ˆå‰æ²¿åŒºåŸŸã€è°ƒæ•´çº¿Sã€è°ƒæ•´çº¿Pã€åæ–¹ä¿éšœåŒºï¼‰
        
        æ ¼å¼ç¤ºä¾‹ï¼š
        å‰æ²¿åŒºåŸŸï¼šå·¦ä¸Šè§’: (118.5, 31.5)å³ä¸‹è§’: (118.552, 31.545)
        è°ƒæ•´çº¿Sï¼šå·¦ä¸Šè§’: (118.5, 31.518)å³ä¸‹è§’: (118.552, 31.563)
        è°ƒæ•´çº¿Pï¼šå·¦ä¸Šè§’: (118.5, 31.536)å³ä¸‹è§’: (118.552, 31.581)
        åæ–¹ä¿éšœåŒºï¼šå·¦ä¸Šè§’: (118.552, 31.581)å³ä¸‹è§’: (118.604, 31.626)
        
        Returns:
            List[Dict]: åŒºåŸŸä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« name, top_left, bottom_right
        """
        regions = []
        
        # åŒ¹é…åŒºåŸŸåç§°å’Œåæ ‡çš„æ¨¡å¼
        # åŒ¹é…æ ¼å¼ï¼šåŒºåŸŸåï¼šå·¦ä¸Šè§’: (lon, lat)å³ä¸‹è§’: (lon, lat)
        pattern = r'([^ï¼š:]+)[ï¼š:]\s*å·¦ä¸Šè§’[ï¼š:]\s*\(([\d.]+),\s*([\d.]+)\)\s*å³ä¸‹è§’[ï¼š:]\s*\(([\d.]+),\s*([\d.]+)\)'
        
        matches = re.finditer(pattern, task_text)
        for match in matches:
            region_name = match.group(1).strip()
            top_left_lon = float(match.group(2))
            top_left_lat = float(match.group(3))
            bottom_right_lon = float(match.group(4))
            bottom_right_lat = float(match.group(5))
            
            regions.append({
                "name": region_name,
                "top_left": (top_left_lon, top_left_lat),
                "bottom_right": (bottom_right_lon, bottom_right_lat)
            })
        
        return regions
